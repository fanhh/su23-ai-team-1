{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "0.14.0+cu117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = 'C:/Users/siddu/SU22_project/cursive_prediction/datafileszipped/datafiles'\n",
    "os.chdir(folder_path)\n",
    "files_in_folder = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dic = {}\n",
    "for file in files_in_folder:\n",
    "    letter = file[-5]\n",
    "    file_dic[file] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(file_dic.items()), columns=['file_name', 'letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000_a.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001_b.png</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002_n.png</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_e.png</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935_i.png</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936_x.png</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938_l.png</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939_r.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name letter\n",
       "0     0000_a.png      a\n",
       "1     0001_b.png      b\n",
       "2     0002_n.png      n\n",
       "3     0003_o.png      o\n",
       "4     0004_e.png      e\n",
       "...          ...    ...\n",
       "1935  1935_i.png      i\n",
       "1936  1936_x.png      x\n",
       "1937  1937_o.png      o\n",
       "1938  1938_l.png      l\n",
       "1939  1939_r.png      r\n",
       "\n",
       "[1940 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def png_to_tensor(path):\n",
    "    # Replace 'path_to_image.png' with the actual path to your PNG file\n",
    "    image_path = folder_path + '/' + path\n",
    "\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    bw_image = image.convert('L')\n",
    "    data_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(), # Scales data into [0,1] \n",
    "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    ]\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    img_tensor = data_transform(bw_image)\n",
    "\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO ADD NOISE \n",
    "def add_gaussian_noise(tensor, mean=0.0, std=0.1):\n",
    "    noise = torch.randn(tensor.size()) * std + mean\n",
    "    noisy_tensor = tensor + noise\n",
    "    return torch.clamp(noisy_tensor, min=-1.0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE TO NOISY TENSOR\n",
    "def png_to_noisy_tensor(path, noise_mean=0.0, noise_std=0.1):\n",
    "    # Replace 'path_to_image.png' with the actual path to your PNG file\n",
    "    image_path = folder_path + '/' + path\n",
    "\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    bw_image = image.convert('L')\n",
    "    data_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(), # Scales data into [0,1] \n",
    "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    ]\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    img_tensor = data_transform(bw_image)\n",
    "\n",
    "    # Add Gaussian noise to the tensor\n",
    "    noisy_img_tensor = add_gaussian_noise(img_tensor, mean=noise_mean, std=noise_std)\n",
    "\n",
    "    return noisy_img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_image(tensor):\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "        transforms.Lambda(lambda t: t * 255.),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage(),\n",
    "    ])\n",
    "    return reverse_transforms(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000_a.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001_b.png</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002_n.png</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_e.png</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935_i.png</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936_x.png</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938_l.png</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939_r.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name letter\n",
       "0     0000_a.png      a\n",
       "1     0001_b.png      b\n",
       "2     0002_n.png      n\n",
       "3     0003_o.png      o\n",
       "4     0004_e.png      e\n",
       "...          ...    ...\n",
       "1935  1935_i.png      i\n",
       "1936  1936_x.png      x\n",
       "1937  1937_o.png      o\n",
       "1938  1938_l.png      l\n",
       "1939  1939_r.png      r\n",
       "\n",
       "[1940 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = df['file_name'].apply(png_to_tensor)\n",
    "df.drop(columns = ['file_name'], inplace = True)\n",
    "df = df[['image', 'letter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5608, 0.5843, 0.6627,  ..., 0.6784, 0.6392, 0.5922],\n",
       "         [0.5373, 0.5843, 0.6549,  ..., 0.6706, 0.6392, 0.6000],\n",
       "         [0.4980, 0.5529, 0.6078,  ..., 0.6471, 0.6235, 0.6000],\n",
       "         ...,\n",
       "         [0.7333, 0.7255, 0.7020,  ..., 0.7333, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7176,  ..., 0.7412, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7255,  ..., 0.7412, 0.7647, 0.7725]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5608, 0.5843, 0.6627,  ..., 0.6784, 0.6392, 0.5922],\n",
       "         [0.5373, 0.5843, 0.6549,  ..., 0.6706, 0.6392, 0.6000],\n",
       "         [0.4980, 0.5529, 0.6078,  ..., 0.6471, 0.6235, 0.6000],\n",
       "         ...,\n",
       "         [0.7333, 0.7255, 0.7020,  ..., 0.7333, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7176,  ..., 0.7412, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7255,  ..., 0.7412, 0.7647, 0.7725]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    noise_df = df2.copy()\n",
    "    noise_df['image'] = noise_df['file_name'].apply(png_to_noisy_tensor)\n",
    "    noise_df.drop(columns = ['file_name'], inplace = True)\n",
    "    noise_df = noise_df[['image', 'letter']]    \n",
    "    df = df.append(noise_df, ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# df to tuples\n",
    "data_tuples = list(zip(df['image'].tolist(), df['letter'].tolist()))\n",
    "\n",
    "# Split indices\n",
    "dataset_size = len(data_tuples)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(0.2 * dataset_size)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Shuffle indices\n",
    "indices_shuffled = torch.randperm(len(indices))\n",
    "\n",
    "# Split \n",
    "train_indices, test_indices = indices_shuffled[split:], indices_shuffled[:split]\n",
    "\n",
    "# custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_tensor, letter = self.data[index]\n",
    "        return image_tensor, ord(letter) - ord('a')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# custom Datasets\n",
    "train_dataset = CustomDataset(data=[data_tuples[i] for i in train_indices])\n",
    "test_dataset = CustomDataset(data=[data_tuples[i] for i in test_indices])\n",
    "\n",
    "#  DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: tensor([[[[1.0000, 0.8657, 0.9670,  ..., 0.9781, 0.9129, 1.0000],\n",
      "          [1.0000, 0.8868, 0.9270,  ..., 0.9154, 1.0000, 0.9166],\n",
      "          [0.8755, 1.0000, 1.0000,  ..., 0.8742, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 0.7935, 1.0000,  ..., 0.9009, 1.0000, 0.9045],\n",
      "          [0.8716, 1.0000, 0.7441,  ..., 0.9688, 0.9644, 1.0000],\n",
      "          [0.9646, 0.8707, 0.6269,  ..., 1.0000, 0.9671, 0.9071]]],\n",
      "\n",
      "\n",
      "        [[[0.8766, 1.0000, 0.7122,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.9496, 0.9385, 1.0000,  ..., 0.9002, 0.9505, 1.0000],\n",
      "          [0.9890, 0.9430, 0.9324,  ..., 1.0000, 0.9005, 0.8240],\n",
      "          ...,\n",
      "          [0.7166, 0.8107, 0.6624,  ..., 0.8010, 0.8060, 0.9374],\n",
      "          [0.8903, 0.9505, 0.9509,  ..., 1.0000, 0.8886, 0.9253],\n",
      "          [0.9944, 1.0000, 1.0000,  ..., 0.8692, 0.9616, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.6321, 0.5455, 0.5228,  ..., 0.8175, 0.7731, 0.6978],\n",
      "          [0.5864, 0.4454, 0.5503,  ..., 0.7412, 0.6202, 0.6066],\n",
      "          [0.6491, 0.7377, 0.5653,  ..., 0.7248, 0.6655, 0.4843],\n",
      "          ...,\n",
      "          [0.6196, 0.4921, 0.5872,  ..., 0.5751, 0.8753, 0.7856],\n",
      "          [0.5295, 0.6272, 0.5763,  ..., 0.7386, 0.5812, 0.4988],\n",
      "          [0.6023, 0.6374, 0.7162,  ..., 0.5350, 0.5445, 0.7514]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.6872, 0.6925, 0.5500,  ..., 0.9608, 0.8660, 0.8227],\n",
      "          [0.7922, 0.6983, 0.6813,  ..., 0.7043, 0.6851, 0.7775],\n",
      "          [0.7255, 0.6510, 0.6744,  ..., 0.7216, 0.7240, 0.6887],\n",
      "          ...,\n",
      "          [0.6269, 0.8111, 0.5880,  ..., 0.7981, 0.6759, 0.7349],\n",
      "          [0.5316, 0.6071, 0.7100,  ..., 0.6605, 0.6765, 0.7407],\n",
      "          [0.6907, 0.6731, 0.7023,  ..., 0.7461, 0.9277, 0.7008]]],\n",
      "\n",
      "\n",
      "        [[[0.6605, 0.4987, 0.5550,  ..., 0.6600, 0.4793, 0.6207],\n",
      "          [0.5730, 0.4745, 0.7336,  ..., 0.5684, 0.4285, 0.4816],\n",
      "          [0.5869, 0.6584, 0.6300,  ..., 0.8128, 0.7290, 0.6661],\n",
      "          ...,\n",
      "          [0.6444, 0.5941, 0.6813,  ..., 0.7056, 0.7020, 0.4981],\n",
      "          [0.7505, 0.7545, 0.6946,  ..., 0.7362, 0.6677, 0.5645],\n",
      "          [0.6419, 0.5546, 0.7937,  ..., 0.7951, 0.4745, 0.8644]]],\n",
      "\n",
      "\n",
      "        [[[0.9064, 0.9689, 0.8326,  ..., 1.0000, 0.7971, 0.8829],\n",
      "          [0.8659, 0.7911, 0.8743,  ..., 0.5765, 0.9423, 0.8296],\n",
      "          [0.9775, 0.8480, 0.9714,  ..., 0.8411, 0.8663, 0.9355],\n",
      "          ...,\n",
      "          [0.4862, 0.3271, 0.2839,  ..., 0.3038, 0.2933, 0.2888],\n",
      "          [0.5654, 0.4509, 0.4852,  ..., 0.4969, 0.1351, 0.2685],\n",
      "          [0.7143, 0.7818, 0.6470,  ..., 0.3724, 0.4380, 0.2450]]]])\n",
      "y batch: tensor([14, 18, 17,  7, 19,  3, 14, 20,  4, 20,  4, 20, 24, 14,  0,  5,  5,  2,\n",
      "        12, 12, 11,  7,  0, 13, 12, 11, 14,  4, 10,  0, 18,  0])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in test_loader:\n",
    "    print(\"X batch:\", X_batch)\n",
    "    print(\"y batch:\", y_batch)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet architecture\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=26):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddu\\AppData\\Local\\Temp\\ipykernel_9504\\1123731909.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.7722884606332814\n",
      "Epoch 2, Loss: 1.5896464276514697\n",
      "Epoch 3, Loss: 0.5629587309428034\n",
      "Epoch 4, Loss: 0.2928874114674799\n",
      "Epoch 5, Loss: 0.17587311396615976\n",
      "Epoch 6, Loss: 0.12047956879983206\n",
      "Epoch 7, Loss: 0.11709189361332147\n",
      "Epoch 8, Loss: 0.029267835329748217\n",
      "Epoch 9, Loss: 0.02597711741858707\n",
      "Epoch 10, Loss: 0.03790932806733314\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "alexnet = AlexNet().to(device)\n",
    "\n",
    "#loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alexnet.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"Training Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddu\\AppData\\Local\\Temp\\ipykernel_9504\\3622266950.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2833216420458213\n",
      "Testing Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = 0.0\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {test_loss/len(test_loader)}\")\n",
    "\n",
    "print(\"Testing Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_img(img):\n",
    "    processed_img = png_to_tensor(img).to(device)\n",
    "    processed_img = processed_img.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        alexnet.eval()\n",
    "        output = alexnet(processed_img)\n",
    "\n",
    "    return chr(torch.argmax(output) + ord('a'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '1939_r.png'\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pred_img(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
